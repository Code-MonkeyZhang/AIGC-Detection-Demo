#!/usr/bin/env python3
"""
AI å›¾ç‰‡æ£€æµ‹å™¨åŸºå‡†æµ‹è¯•è„šæœ¬

åœ¨ wildData æ•°æ®é›†ä¸Šè¯„ä¼°ä¸åŒæ£€æµ‹å™¨çš„æ€§èƒ½

ä½¿ç”¨æ–¹æ³•:
    python benchmark_test.py [--mode MODE] [--samples N]
    
    --mode: all|sightengine|mini|full|advanced (é»˜è®¤: all)
    --samples: æµ‹è¯•æ ·æœ¬æ•° (é»˜è®¤: 100)
"""

import os
import sys
import random
import pandas as pd
import json
import time
import argparse
from pathlib import Path
from typing import List, Dict
from tqdm import tqdm

# å¯¼å…¥æ£€æµ‹å™¨
from detectors import (
    SightEngineDetector,
    NonescapeMiniDetector,
    NonescapeFullDetector,
    AdvancedDetector
)
from utils.metrics import calculate_metrics, print_metrics


# ==================== é…ç½®åŒºåŸŸ ====================

# SightEngine API é…ç½®
SIGHTENGINE_API_USER = "1130240739"
SIGHTENGINE_API_SECRET = "2EMcFiUxsHjn6FbJyn2ZeDgKkKJBZDzM"

# æ¨¡å‹è·¯å¾„
MODEL_MINI_PATH = "model/nonescape-mini-v0.safetensors"
MODEL_FULL_PATH = "model/nonescape-v0.safetensors"

# æ•°æ®é›†é…ç½®
DATASET_DIR = "data/wildData/full_dataset"
TRAIN_CSV = "data/wildData/full_dataset/train.csv"

# ç»“æœä¿å­˜ç›®å½•
RESULTS_DIR = "benchmark_results"

# éšæœºç§å­
RANDOM_SEED = 42

# ç»„åˆæ£€æµ‹å™¨æƒé‡é…ç½®
ADVANCED_WEIGHTS = {
    "SightEngine": 0.5,
    "Nonescape-Mini": 0.5
}

# ==================================================


def load_dataset(csv_path: str, dataset_dir: str, num_samples: int, seed: int) -> pd.DataFrame:
    """
    åŠ è½½æ•°æ®é›†å¹¶éšæœºé‡‡æ ·
    
    Args:
        csv_path: CSV æ–‡ä»¶è·¯å¾„
        dataset_dir: æ•°æ®é›†æ ¹ç›®å½•
        num_samples: é‡‡æ ·æ•°é‡
        seed: éšæœºç§å­
        
    Returns:
        é‡‡æ ·åçš„ DataFrame
    """
    print(f"\nğŸ“‚ åŠ è½½æ•°æ®é›†: {csv_path}")
    df = pd.read_csv(csv_path)
    print(f"   æ€»æ ·æœ¬æ•°: {len(df)}")
    
    # è®¾ç½®éšæœºç§å­
    random.seed(seed)
    
    # éšæœºé‡‡æ ·
    if num_samples < len(df):
        sample_df = df.sample(n=num_samples, random_state=seed)
        print(f"   éšæœºé‡‡æ ·: {num_samples} ä¸ªæ ·æœ¬")
    else:
        sample_df = df
        print(f"   ä½¿ç”¨å…¨éƒ¨æ ·æœ¬")
    
    # æ·»åŠ å®Œæ•´è·¯å¾„
    sample_df['full_path'] = sample_df['file_name'].apply(
        lambda x: os.path.join(dataset_dir, x)
    )
    
    # ç»Ÿè®¡æ ‡ç­¾åˆ†å¸ƒ
    label_counts = sample_df['label'].value_counts()
    print(f"   æ ‡ç­¾åˆ†å¸ƒ:")
    print(f"     Real (0): {label_counts.get(0, 0)} ({label_counts.get(0, 0)/len(sample_df)*100:.1f}%)")
    print(f"     AI (1):   {label_counts.get(1, 0)} ({label_counts.get(1, 0)/len(sample_df)*100:.1f}%)")
    
    return sample_df


def test_detector(detector, sample_df: pd.DataFrame, desc: str) -> Dict:
    """
    æµ‹è¯•å•ä¸ªæ£€æµ‹å™¨
    
    Args:
        detector: æ£€æµ‹å™¨å®ä¾‹
        sample_df: æ ·æœ¬æ•°æ®
        desc: è¿›åº¦æ¡æè¿°
        
    Returns:
        æµ‹è¯•ç»“æœå­—å…¸
    """
    print(f"\nğŸ” å¼€å§‹æµ‹è¯•: {detector.get_name()}")
    
    y_true = []
    y_pred = []
    y_scores = []
    failed_count = 0
    
    start_time = time.time()
    
    for idx, row in tqdm(sample_df.iterrows(), total=len(sample_df), desc=desc):
        img_path = row['full_path']
        true_label = row['label']
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(img_path):
            print(f"   âš ï¸  æ–‡ä»¶ä¸å­˜åœ¨: {img_path}")
            y_true.append(true_label)
            y_pred.append(None)
            y_scores.append(None)
            failed_count += 1
            continue
        
        # è¿›è¡Œé¢„æµ‹
        result = detector.predict(img_path)
        
        y_true.append(true_label)
        y_pred.append(result['prediction'])
        y_scores.append(result['score'])
        
        if result['error']:
            failed_count += 1
    
    elapsed_time = time.time() - start_time
    
    print(f"   å®Œæˆæ—¶é—´: {elapsed_time:.2f} ç§’")
    print(f"   å¹³å‡æ¯å¼ : {elapsed_time/len(sample_df):.2f} ç§’")
    if failed_count > 0:
        print(f"   âš ï¸  å¤±è´¥æ•°é‡: {failed_count}")
    
    # è®¡ç®—æŒ‡æ ‡
    metrics = calculate_metrics(y_true, y_pred, y_scores)
    metrics['elapsed_time'] = elapsed_time
    metrics['avg_time_per_image'] = elapsed_time / len(sample_df)
    
    return {
        'detector_name': detector.get_name(),
        'metrics': metrics,
        'predictions': {
            'y_true': y_true,
            'y_pred': y_pred,
            'y_scores': y_scores
        }
    }


def save_results(results: List[Dict], mode: str):
    """ä¿å­˜æµ‹è¯•ç»“æœ"""
    os.makedirs(RESULTS_DIR, exist_ok=True)
    
    simplified_results = []
    for result in results:
        simplified = {
            'detector_name': result['detector_name'],
            'metrics': result['metrics']
        }
        simplified_results.append(simplified)
    
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    output_file = os.path.join(RESULTS_DIR, f"{mode}_{timestamp}.json")
    
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(simplified_results, f, ensure_ascii=False, indent=2)
        print(f"\nâœ… ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    except Exception as e:
        print(f"\nâš ï¸  ä¿å­˜ç»“æœå¤±è´¥: {e}")


def print_comparison(results: List[Dict]):
    """
    æ‰“å°å¯¹æ¯”ç»“æœ
    
    Args:
        results: æ‰€æœ‰æµ‹è¯•ç»“æœ
    """
    print(f"\n{'='*70}")
    print("ğŸ“ˆ æ€§èƒ½å¯¹æ¯”æ€»ç»“")
    print(f"{'='*70}")
    
    print(f"\n{'æ£€æµ‹å™¨':<20} {'å‡†ç¡®ç‡':<12} {'F1åˆ†æ•°':<12} {'ROC-AUC':<12} {'å¹³å‡è€—æ—¶'}")
    print("-" * 70)
    
    for result in results:
        name = result['detector_name']
        metrics = result['metrics']
        
        if 'error' not in metrics:
            print(f"{name:<20} {metrics['accuracy']:<12.4f} {metrics['f1_score']:<12.4f} "
                  f"{metrics['roc_auc']:<12.4f} {metrics['avg_time_per_image']:.2f}s")
    
    # æ‰¾å‡ºæœ€ä½³æ¨¡å‹
    print(f"\n{'='*70}")
    print("ğŸ† æœ€ä½³æ¨¡å‹")
    print(f"{'='*70}")
    
    valid_results = [r for r in results if 'error' not in r['metrics']]
    
    if valid_results:
        best_accuracy = max(valid_results, key=lambda x: x['metrics']['accuracy'])
        best_f1 = max(valid_results, key=lambda x: x['metrics']['f1_score'])
        best_auc = max(valid_results, key=lambda x: x['metrics']['roc_auc'])
        fastest = min(valid_results, key=lambda x: x['metrics']['avg_time_per_image'])
        
        print(f"  æœ€é«˜å‡†ç¡®ç‡: {best_accuracy['detector_name']} "
              f"({best_accuracy['metrics']['accuracy']:.4f})")
        print(f"  æœ€é«˜F1åˆ†æ•°: {best_f1['detector_name']} "
              f"({best_f1['metrics']['f1_score']:.4f})")
        print(f"  æœ€é«˜ROC-AUC: {best_auc['detector_name']} "
              f"({best_auc['metrics']['roc_auc']:.4f})")
        print(f"  æœ€å¿«é€Ÿåº¦: {fastest['detector_name']} "
              f"({fastest['metrics']['avg_time_per_image']:.2f}s/å›¾)")


def main():
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description="AI å›¾ç‰‡æ£€æµ‹å™¨åŸºå‡†æµ‹è¯•")
    parser.add_argument('--mode', type=str, default='all', 
                        choices=['all', 'sightengine', 'mini', 'full', 'advanced'],
                        help='æµ‹è¯•æ¨¡å¼: all|sightengine|mini|full|advanced')
    parser.add_argument('--samples', type=int, default=100,
                        help='æµ‹è¯•æ ·æœ¬æ•°')
    args = parser.parse_args()
    
    print("=" * 70)
    print("AI å›¾ç‰‡æ£€æµ‹å™¨åŸºå‡†æµ‹è¯•")
    print(f"æµ‹è¯•æ¨¡å¼: {args.mode}")
    print(f"æ ·æœ¬æ•°: {args.samples}")
    print("=" * 70)
    
    # 1. åŠ è½½æ•°æ®é›†
    sample_df = load_dataset(TRAIN_CSV, DATASET_DIR, args.samples, RANDOM_SEED)
    
    # 2. åˆå§‹åŒ–æ£€æµ‹å™¨
    print(f"\n{'='*70}")
    print("ğŸ”§ åˆå§‹åŒ–æ£€æµ‹å™¨")
    print(f"{'='*70}")
    
    mode = args.mode
    detectors = []
    detector_configs = []
    
    # SightEngine
    if mode in ['all', 'sightengine', 'advanced']:
        try:
            sightengine = SightEngineDetector(SIGHTENGINE_API_USER, SIGHTENGINE_API_SECRET)
            detectors.append(sightengine)
            if mode in ['all', 'sightengine']:
                detector_configs.append(('sightengine', sightengine))
        except Exception as e:
            print(f"âš ï¸  SightEngine åˆå§‹åŒ–å¤±è´¥: {e}")
    
    # Nonescape Mini
    if mode in ['all', 'mini', 'advanced']:
        try:
            if os.path.exists(MODEL_MINI_PATH):
                nonescape_mini = NonescapeMiniDetector(MODEL_MINI_PATH)
                detectors.append(nonescape_mini)
                if mode in ['all', 'mini']:
                    detector_configs.append(('mini', nonescape_mini))
            else:
                print(f"âš ï¸  æ‰¾ä¸åˆ° Mini æ¨¡å‹: {MODEL_MINI_PATH}")
        except Exception as e:
            print(f"âš ï¸  Nonescape Mini åˆå§‹åŒ–å¤±è´¥: {e}")
    
    # Nonescape Full
    if mode in ['all', 'full']:
        try:
            if os.path.exists(MODEL_FULL_PATH):
                nonescape_full = NonescapeFullDetector(MODEL_FULL_PATH)
                detectors.append(nonescape_full)
                detector_configs.append(('full', nonescape_full))
            else:
                print(f"âš ï¸  æ‰¾ä¸åˆ° Full æ¨¡å‹: {MODEL_FULL_PATH}")
        except Exception as e:
            print(f"âš ï¸  Nonescape Full åˆå§‹åŒ–å¤±è´¥: {e}")
    
    # Advanced (ç»„åˆ)
    if mode in ['all', 'advanced']:
        try:
            sightengine_det = None
            mini_det = None
            
            for d in detectors:
                if d.get_name() == "SightEngine":
                    sightengine_det = d
                elif d.get_name() == "Nonescape-Mini":
                    mini_det = d
            
            if sightengine_det and mini_det:
                advanced_weights = [
                    ADVANCED_WEIGHTS.get("SightEngine", 0.5),
                    ADVANCED_WEIGHTS.get("Nonescape-Mini", 0.5)
                ]
                total = sum(advanced_weights)
                advanced_weights = [w/total for w in advanced_weights]
                
                advanced = AdvancedDetector([sightengine_det, mini_det], advanced_weights)
                detector_configs.append(('advanced', advanced))
            else:
                print(f"âš ï¸  Advanced éœ€è¦ SightEngine å’Œ Nonescape-Mini")
        except Exception as e:
            print(f"âš ï¸  Advanced åˆå§‹åŒ–å¤±è´¥: {e}")
    
    if not detector_configs:
        print("âŒ æ²¡æœ‰å¯ç”¨çš„æ£€æµ‹å™¨ï¼")
        sys.exit(1)
    
    # 3. è¿è¡Œæµ‹è¯•
    results = []
    for name, detector in detector_configs:
        result = test_detector(detector, sample_df, f"æµ‹è¯• {detector.get_name()}")
        results.append(result)
        print_metrics(detector.get_name(), result['metrics'])
    
    # 4. æ‰“å°å¯¹æ¯”ç»“æœ
    print_comparison(results)
    
    # 5. ä¿å­˜ç»“æœ
    save_results(results, args.mode)
    
    print(f"\n{'='*70}")
    print("âœ… æ‰€æœ‰æµ‹è¯•å®Œæˆ!")
    print(f"{'='*70}")


if __name__ == "__main__":
    main()

